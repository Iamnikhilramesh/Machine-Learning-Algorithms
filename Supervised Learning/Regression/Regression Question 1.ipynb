{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta1</th>\n",
       "      <th>theta2</th>\n",
       "      <th>theta3</th>\n",
       "      <th>theta4</th>\n",
       "      <th>theta5</th>\n",
       "      <th>theta6</th>\n",
       "      <th>theta7</th>\n",
       "      <th>theta8</th>\n",
       "      <th>alpha1</th>\n",
       "      <th>alpha2</th>\n",
       "      <th>...</th>\n",
       "      <th>a8</th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "      <th>d5</th>\n",
       "      <th>d6</th>\n",
       "      <th>d7</th>\n",
       "      <th>d8</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "      <td>8192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.000355</td>\n",
       "      <td>0.001292</td>\n",
       "      <td>0.001170</td>\n",
       "      <td>-0.001491</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>-0.000720</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>...</td>\n",
       "      <td>0.211359</td>\n",
       "      <td>0.147800</td>\n",
       "      <td>0.149082</td>\n",
       "      <td>0.149806</td>\n",
       "      <td>0.150975</td>\n",
       "      <td>0.150581</td>\n",
       "      <td>0.148654</td>\n",
       "      <td>0.150665</td>\n",
       "      <td>0.148251</td>\n",
       "      <td>1.800938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.182322</td>\n",
       "      <td>0.180830</td>\n",
       "      <td>0.181815</td>\n",
       "      <td>0.183597</td>\n",
       "      <td>0.180371</td>\n",
       "      <td>0.181936</td>\n",
       "      <td>0.182643</td>\n",
       "      <td>0.181537</td>\n",
       "      <td>0.321380</td>\n",
       "      <td>0.321990</td>\n",
       "      <td>...</td>\n",
       "      <td>0.137429</td>\n",
       "      <td>0.150246</td>\n",
       "      <td>0.150367</td>\n",
       "      <td>0.150253</td>\n",
       "      <td>0.150391</td>\n",
       "      <td>0.150488</td>\n",
       "      <td>0.150304</td>\n",
       "      <td>0.150460</td>\n",
       "      <td>0.150515</td>\n",
       "      <td>0.395336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.314100</td>\n",
       "      <td>-0.314117</td>\n",
       "      <td>-0.314082</td>\n",
       "      <td>-0.314127</td>\n",
       "      <td>-0.314135</td>\n",
       "      <td>-0.314110</td>\n",
       "      <td>-0.314116</td>\n",
       "      <td>-0.314031</td>\n",
       "      <td>-0.392699</td>\n",
       "      <td>-0.392699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.157064</td>\n",
       "      <td>-0.154740</td>\n",
       "      <td>-0.158420</td>\n",
       "      <td>-0.161679</td>\n",
       "      <td>-0.154140</td>\n",
       "      <td>-0.158087</td>\n",
       "      <td>-0.156950</td>\n",
       "      <td>-0.157968</td>\n",
       "      <td>-0.392699</td>\n",
       "      <td>-0.392699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.533121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.004563</td>\n",
       "      <td>0.003349</td>\n",
       "      <td>0.004674</td>\n",
       "      <td>-0.002177</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>-0.001178</td>\n",
       "      <td>-0.003387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266808</td>\n",
       "      <td>0.259524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.264788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.808037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.158190</td>\n",
       "      <td>0.158474</td>\n",
       "      <td>0.159908</td>\n",
       "      <td>0.156626</td>\n",
       "      <td>0.155948</td>\n",
       "      <td>0.160228</td>\n",
       "      <td>0.156914</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305363</td>\n",
       "      <td>0.299725</td>\n",
       "      <td>0.299753</td>\n",
       "      <td>0.299873</td>\n",
       "      <td>0.300184</td>\n",
       "      <td>0.300504</td>\n",
       "      <td>0.299939</td>\n",
       "      <td>0.300166</td>\n",
       "      <td>0.300057</td>\n",
       "      <td>2.075908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.314021</td>\n",
       "      <td>0.314071</td>\n",
       "      <td>0.314062</td>\n",
       "      <td>0.314158</td>\n",
       "      <td>0.314159</td>\n",
       "      <td>0.314150</td>\n",
       "      <td>0.314126</td>\n",
       "      <td>0.313977</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>0.392699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351547</td>\n",
       "      <td>0.359897</td>\n",
       "      <td>0.343076</td>\n",
       "      <td>0.356919</td>\n",
       "      <td>0.358765</td>\n",
       "      <td>0.345783</td>\n",
       "      <td>0.361700</td>\n",
       "      <td>0.347777</td>\n",
       "      <td>0.349389</td>\n",
       "      <td>3.077484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            theta1       theta2       theta3       theta4       theta5  \\\n",
       "count  8192.000000  8192.000000  8192.000000  8192.000000  8192.000000   \n",
       "mean     -0.000355     0.001292     0.001170    -0.001491     0.000400   \n",
       "std       0.182322     0.180830     0.181815     0.183597     0.180371   \n",
       "min      -0.314100    -0.314117    -0.314082    -0.314127    -0.314135   \n",
       "25%      -0.157064    -0.154740    -0.158420    -0.161679    -0.154140   \n",
       "50%      -0.004563     0.003349     0.004674    -0.002177     0.000607   \n",
       "75%       0.161290     0.158190     0.158474     0.159908     0.156626   \n",
       "max       0.314021     0.314071     0.314062     0.314158     0.314159   \n",
       "\n",
       "            theta6       theta7       theta8       alpha1       alpha2  \\\n",
       "count  8192.000000  8192.000000  8192.000000  8192.000000  8192.000000   \n",
       "mean      0.000572     0.000235    -0.000720     0.000192     0.006376   \n",
       "std       0.181936     0.182643     0.181537     0.321380     0.321990   \n",
       "min      -0.314110    -0.314116    -0.314031    -0.392699    -0.392699   \n",
       "25%      -0.158087    -0.156950    -0.157968    -0.392699    -0.392699   \n",
       "50%       0.002037    -0.001178    -0.003387     0.000000     0.000000   \n",
       "75%       0.155948     0.160228     0.156914     0.392699     0.392699   \n",
       "max       0.314150     0.314126     0.313977     0.392699     0.392699   \n",
       "\n",
       "          ...                a8           d1           d2           d3  \\\n",
       "count     ...       8192.000000  8192.000000  8192.000000  8192.000000   \n",
       "mean      ...          0.211359     0.147800     0.149082     0.149806   \n",
       "std       ...          0.137429     0.150246     0.150367     0.150253   \n",
       "min       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "25%       ...          0.000000     0.000000     0.000000     0.000000   \n",
       "50%       ...          0.292031     0.000000     0.000000     0.000000   \n",
       "75%       ...          0.305363     0.299725     0.299753     0.299873   \n",
       "max       ...          0.351547     0.359897     0.343076     0.356919   \n",
       "\n",
       "                d4           d5           d6           d7           d8  \\\n",
       "count  8192.000000  8192.000000  8192.000000  8192.000000  8192.000000   \n",
       "mean      0.150975     0.150581     0.148654     0.150665     0.148251   \n",
       "std       0.150391     0.150488     0.150304     0.150460     0.150515   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.266808     0.259524     0.000000     0.264788     0.000000   \n",
       "75%       0.300184     0.300504     0.299939     0.300166     0.300057   \n",
       "max       0.358765     0.345783     0.361700     0.347777     0.349389   \n",
       "\n",
       "                 y  \n",
       "count  8192.000000  \n",
       "mean      1.800938  \n",
       "std       0.395336  \n",
       "min       0.366801  \n",
       "25%       1.533121  \n",
       "50%       1.808037  \n",
       "75%       2.075908  \n",
       "max       3.077484  \n",
       "\n",
       "[8 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the dataset\n",
    "df1 = pd.read_csv('kin-32fm.csv')\n",
    "df1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8192, 32)\n",
      "(8192,)\n"
     ]
    }
   ],
   "source": [
    "#spliting data into x and y\n",
    "x=df1.drop(['y'],axis=1)\n",
    "y=df1['y']\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5734, 32)\n",
      "(2458, 32)\n",
      "(5734,)\n",
      "(2458,)\n"
     ]
    }
   ],
   "source": [
    "#spliting data into train and test\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9075779205782498"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating LinearRegression model\n",
    "model_2 = LinearRegression()\n",
    "model_2.fit(x_train,y_train)\n",
    "#predicting the test data\n",
    "y2_predict = model_2.predict(x_test)\n",
    "\n",
    "#Checking the accuracy of the model\n",
    "from sklearn.metrics import r2_score\n",
    "r2_score(y_test, y2_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.49922345239833\n"
     ]
    }
   ],
   "source": [
    "# mean squared error\n",
    "mse = np.sum((y2_predict - y_test)**2)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1).Select  a  dataset  from  the  repository,  select  a  suitable  algorithm  to  evaluate  and  use  the holdout method to estimate the future performance.\n",
    "a.What performance can be expected on your problem? \n",
    "-->Performance is 90.75%.\n",
    "\n",
    "b.How confident can you be that your estimate is close to the true performance?\n",
    "-->I am 65% Confident that my model is close to the true performace\n",
    "\n",
    "c.How does the size of the training/test sets affect the reliability?\n",
    "-->These numbers can vary - a larger percentage of test data will make your model more prone to errors as it has less training experience, while a smaller percentage of test data may give your model an unwanted bias towards the training data. This lack of training or bias can lead to Underfitting/Overfitting of our model.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
